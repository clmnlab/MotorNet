{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34502d68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ReplayBuffer' from 'buffer' (/mnt/ext1/sungshinkim/Projects/MotorNet/buffer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbuffer\u001b[39;00m \n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reload\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\n\u001b[32m     18\u001b[39m reload(agents)\n\u001b[32m     19\u001b[39m reload(utils)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/ext1/sungshinkim/Projects/MotorNet/agents.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Normal\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRUPolicy, ActorCriticGRU, QNetwork\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbuffer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReplayBuffer \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# from networks.py와 buffer.py에서 필요한 클래스를 가져옵니다.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 이 코드는 Soft Actor-Critic (SAC) 에이전트를 구현합니다.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# SAC 에이전트는 연속적인 행동 공간을 가진 강화 학습 문제를 해결하기 위해 설계되었습니다.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 이 에이전트는 정책 네트워크와 Q-네트워크를 사용하여 최적의 행동을 선택하고 학습합니다.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 이 코드는 PyTorch를 사용하여 구현되었으며, GRU 기반의 정책 네트워크와 MLP 기반의 Q-네트워크를 포함합니다. \u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ReplayBuffer' from 'buffer' (/mnt/ext1/sungshinkim/Projects/MotorNet/buffer.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import motornet as mn\n",
    "import utils\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import json    \n",
    "import task \n",
    "import buffer \n",
    "from importlib import reload\n",
    "import agents\n",
    "reload(agents)\n",
    "reload(utils)\n",
    "reload(task)\n",
    "reload(buffer)\n",
    "from utils import load_env, load_policy, calc_loss, run_rollout\n",
    "from task import CentreOutFFGym, CentreOutFF\n",
    "from buffer import RolloutBuffer\n",
    "from agents import SLAgent, GRUPPOAgent\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25eab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 시작 (총 50000 스텝) on cuda...\n"
     ]
    }
   ],
   "source": [
    "TOTAL_TIMESTEPS = 50000\n",
    "N_STEPS = 2048  # 데이터 수집 스텝 수\n",
    "HIDDEN_DIM = 128\n",
    "config = 'params.json'\n",
    "with open(config, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# --- parameters setting ---\n",
    "env_params = config['env_params']\n",
    "train_params = config['training_params']\n",
    "\n",
    "effector = mn.effector.RigidTendonArm26(muscle=mn.muscle.RigidTendonHillMuscle())\n",
    "\n",
    "# --- 환경 및 에이전트 생성 ---\n",
    "env = CentreOutFFGym(effector=effector, **env_params)\n",
    "env_org = CentreOutFF(effector=effector, **env_params)\n",
    "\n",
    "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "agent = GRUPPOAgent(env, hidden_dim=HIDDEN_DIM, device=device)\n",
    "buffer = RolloutBuffer(env.observation_space.shape[0], env.action_space.shape[0])\n",
    "\n",
    "\n",
    "print(f\"훈련 시작 (총 {TOTAL_TIMESTEPS} 스텝) on {device}...\")\n",
    "start_time = time.time()\n",
    "\n",
    "obs, _ = env.reset(options={'batch_size': train_params['batch_size']})\n",
    "hidden_state = agent.network.init_hidden(train_params['batch_size'], device)\n",
    "\n",
    "episode_rewards = []\n",
    "current_episode_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b3b9314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_tensor = th.from_numpy(obs).float().to(device)\n",
    "action, value, log_prob, next_hidden_state = agent.select_action(obs_tensor, hidden_state)\n",
    "\n",
    "next_obs, reward, terminated, truncated, info = env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6a80dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.add(obs, action, reward, terminated, log_prob, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c8c19557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<buffer.RolloutBuffer at 0x753f94cd6dd0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "892978ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.states\n",
    "goal_th = env.goal\n",
    "\n",
    "cost_pos = th.sum(th.square(states['fingertip'][:, :2] - goal_th),dim=1)\n",
    "current_vel = states['cartesian'][:, 2:]\n",
    "jerk = current_vel - 2 * env.last_vel + env.prev_last_vel\n",
    "cost_jerk = th.sum(th.square(jerk),dim=1)\n",
    "muscle_force = states['muscle'][:, 4:5, :]\n",
    "cost_muscle = th.sum(th.square(muscle_force),dim=2).squeeze()\n",
    "muscle_force_derivative = muscle_force - env.last_force\n",
    "cost_muscle_derivative = th.sum(th.square(muscle_force_derivative),dim=2).squeeze()\n",
    "total_cost = (env.loss_weights['position'] * cost_pos +\n",
    "                env.loss_weights['jerk'] * cost_jerk +\n",
    "                env.loss_weights['muscle'] * cost_muscle +\n",
    "                env.loss_weights['muscle_derivative'] * cost_muscle_derivative)\n",
    "reward = -(total_cost / 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be9329b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395df27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ab6bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SLAgent(obs_dim=17, action_dim=6, \n",
    "                batch_size = train_params['batch_size'], \n",
    "                device='cpu', lr=1e-4)\n",
    "batch_size = 64\n",
    "h = agent.policy_net.init_hidden(batch_size = batch_size)\n",
    "obs, info = env_org.reset(condition='train', options={'batch_size': batch_size})\n",
    "h.shape, obs.shape\n",
    "action, h = agent.policy_net(obs,h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9530ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, terminated, info = env_org.step(action=action.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bbc1f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3f25ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [1] at index 0 does not match the shape of the indexed tensor [64, 2] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m a, b, c = \u001b[43menv_org\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/ext1/sungshinkim/Projects/MotorNet/task.py:158\u001b[39m, in \u001b[36mCentreOutFF.step\u001b[39m\u001b[34m(self, action, deterministic)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.endpoint_load = get_endpoint_load(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    157\u001b[39m mask = \u001b[38;5;28mself\u001b[39m.elapsed < (\u001b[38;5;28mself\u001b[39m.go_cue_time + (\u001b[38;5;28mself\u001b[39m.vision_delay) * \u001b[38;5;28mself\u001b[39m.dt)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendpoint_load\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m = \u001b[32m0\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# calculate endpoint force (Internal force)\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28mself\u001b[39m.endpoint_force = get_endpoint_force(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: The shape of the mask [1] at index 0 does not match the shape of the indexed tensor [64, 2] at index 0"
     ]
    }
   ],
   "source": [
    "a, b, c = env_org.step(th.from_numpy(action))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motornet_sb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
